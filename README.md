
# ğŸ“„ DocumentaÃ§Ã£o do Projeto â€” Pipeline Azure + Databricks

## ğŸ¢ Sobre os Dados

Os dados utilizados neste projeto sÃ£o provenientes de **uma empresa do setor aeronÃ¡utico**, contendo informaÃ§Ãµes detalhadas sobre ocorrÃªncias envolvendo aeronaves. Eles incluem campos como o nÃºmero de lesÃµes fatais, graves, leves, nÃºmero total de pessoas a bordo, local, estado, e outros indicadores relevantes para anÃ¡lise de seguranÃ§a e operaÃ§Ãµes.

O objetivo Ã© transformar e preparar esses dados para anÃ¡lises avanÃ§adas, garantindo qualidade e confiabilidade nas camadas finais do Data Lake.

---

## ğŸ— Recursos Criados

âœ… Grupo de Armazenamento (Resource Group) â€” criado no Azure  
âœ… Conta de Armazenamento (Storage Account) â€” criada para armazenar dados em diferentes camadas (Bronze, Silver, Gold)  
âœ… Container â€” configurado dentro da Storage Account  
âœ… Pastas â€” organizadas dentro do container (para cada camada do Data Lake)  
âœ… Registro â€” criado para gerenciar acessos  

---

## ğŸ“Œ VisÃ£o Geral do Projeto

Este projeto teve como objetivo **realizar transformaÃ§Ãµes de dados brutos usando recursos do Azure e Databricks**, seguindo o conceito de Data Lakehouse com as camadas:  

- **Bronze** â†’ Dados brutos, diretamente extraÃ­dos da fonte  
- **Silver** â†’ Dados tratados (ex.: limpeza de nulos, conversÃ£o de tipos, ajustes bÃ¡sicos)  
- **Gold** â†’ Dados prontos para anÃ¡lise final e consumo, com agregaÃ§Ãµes e colunas adicionais

---

## âš™ Tecnologias e Ferramentas Utilizadas

- Azure Storage Account  
- Azure Databricks  
- Apache Spark (PySpark)  
- GitHub  
- Azure Data Factory (ADF)  
- Databricks Workflows  

---

## ğŸ“‚ Estrutura das Camadas

| Camada   | DescriÃ§Ã£o                                                                 |
|----------|---------------------------------------------------------------------------|
| Bronze   | Armazenamento inicial dos dados brutos, sem nenhum tratamento             |
| Silver   | Dados parcialmente transformados, com limpeza de colunas e tipos ajustados |
| Gold     | Dados prontos para consumo analÃ­tico, com cÃ¡lculos agregados e particionados por Estado |

---

## ğŸ”„ Fluxo de Processamento

1ï¸âƒ£ Dados brutos armazenados na camada Bronze â†’  
2ï¸âƒ£ Leitura no Databricks Notebook â†’  
3ï¸âƒ£ TransformaÃ§Ãµes aplicadas, incluindo:  
- SeleÃ§Ã£o de colunas relevantes  
- CriaÃ§Ã£o da coluna `Total_Lesoes` somando lesÃµes fatais, graves, leves e ilesos  
- SubstituiÃ§Ã£o de valores nulos em colunas de texto para `'Sem Registro'`  
- ConversÃ£o de colunas string para inteiro onde necessÃ¡rio  
- RenomeaÃ§Ã£o de colunas para nomes mais intuitivos  
- Filtragem de estados indesejados (`Indeterminado`, `Sem Registro`, `Exterior`)  
- InclusÃ£o de coluna com timestamp de atualizaÃ§Ã£o  
4ï¸âƒ£ Escrita final na camada Gold, atualmente em formato **Parquet** 

---

## ğŸ’¡ Aprendizados e ConsideraÃ§Ãµes

âœ… CriaÃ§Ã£o e configuraÃ§Ã£o de pipelines no **Azure Data Factory**  
âœ… OrquestraÃ§Ã£o de notebooks com **Databricks Workflows**  
âœ… IntegraÃ§Ã£o do Databricks ao **GitHub** para versionamento  
âœ… ConfiguraÃ§Ã£o de permissÃµes entre Databricks e Azure  
âœ… Entendimento de que, mesmo excluindo arquivos no Azure, a reexecuÃ§Ã£o do pipeline consegue repovoar os dados automaticamente


#EvidÃªncias: 

![ExecuÃ§Ã£o bem sucedida](./Images/execucao.png)


